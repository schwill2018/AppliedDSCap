{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Function to extract data from zipwho.com\n",
    "def zip_demographics(neighborhood_zip):\n",
    "    \"\"\"Function extracts data from zipwho. Firefox emulation to retrieve data. Tra and except for zip codes\n",
    "    with no current data. Extract data from result string with string manipulation and list manipulation\"\"\"\n",
    "    zip_list = []\n",
    "    zip_list_nan = ['N/A' for i in range(37)]  #add N/A for all 37 demographic entries\n",
    "    for i in range(len(neighborhood_zip)):\n",
    "        url_zip = 'https://zipwho.com/?zip={}-&city=&filters=--_--_--_--&state=&mode=zip'.format(neighborhood_zip['Postal Code'][i])\n",
    "        #emulate Firefox to avoid dread 403 Forbidden\n",
    "        headers ={'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "        page=requests.get(url_zip, headers=headers)                 #Creat soup with requests and BS4\n",
    "        page=page.text\n",
    "        soup=BeautifulSoup(page,features=\"html.parser\")\n",
    "        start_index = str(soup.contents[4]).index('return')\n",
    "        end_index = str(soup.contents[4]).index('}')\n",
    "        #if no data present append N/A list\n",
    "        try:\n",
    "            string_data = str(soup.contents[4])[start_index+8:end_index-4]\n",
    "            string_data_split = string_data.split('\\\\n')\n",
    "            data = string_data_split[1].split(',')\n",
    "            numbers = string_data_split[0].split(',')\n",
    "            zip_list.append(data)\n",
    "        except IndexError:\n",
    "            zip_list.append(zip_list_nan)\n",
    "    zip_list_pd = pd.DataFrame(zip_list, columns = numbers)\n",
    "    zip_list_pd.rename(columns ={'zip':'zip_code'}, inplace = True)\n",
    "    zip_list_pd.drop(columns=['city', 'state'], inplace=True)\n",
    "    return zip_list_pd\n",
    "\n",
    "url_zip = 'https://zipwho.com/?zip={}-&city=&filters=--_--_--_--&state=&mode=zip'.format(75225)\n",
    "\n",
    "headers ={'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}\n",
    "page=requests.get(url_zip)                #Creat soup with requests and BS4\n",
    "page=page.text\n",
    "soup=BeautifulSoup(page,features=\"html.parser\")\n",
    "soup\n",
    "\n",
    "start_index = str(soup.contents[4]).index('return')\n",
    "end_index = str(soup.contents[4]).index('}')\n",
    "print(start_index)\n",
    "print(end_index)\n",
    "\n",
    "string_data = str(soup.contents[4])[start_index+8:end_index-4]\n",
    "string_data_split = string_data.split('\\\\n')\n",
    "\n",
    "print(string_data)\n",
    "print(string_data_split)\n",
    "data = string_data_split[1].split(',')\n",
    "numbers = string_data_split[0].split(',')\n",
    "print(data)\n",
    "\n",
    "#get demographics with zip code data\n",
    "master_demo_list = zip_demographics(data_mast)\n",
    "master_demo_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
